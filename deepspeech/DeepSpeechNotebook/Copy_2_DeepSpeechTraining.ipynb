{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy 2 DeepSpeechTraining",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9MeYFqxo95C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aefafb5-5bf6-4865-e6de-35be0e8e0355"
      },
      "source": [
        "! git clone https://github.com/mozilla/DeepSpeech\n",
        "#! git fetch origin && git checkout origin/master"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeepSpeech'...\n",
            "remote: Enumerating objects: 87, done.\u001b[K\n",
            "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 22499 (delta 40), reused 76 (delta 35), pack-reused 22412\u001b[K\n",
            "Receiving objects: 100% (22499/22499), 48.80 MiB | 14.59 MiB/s, done.\n",
            "Resolving deltas: 100% (15511/15511), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMe6Q7dOAawV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6421fb00-0300-4238-ab67-d5f608dfb0f7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKQkoUO5qvo8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7529b62-94d4-4cc7-b046-b30a02da35db"
      },
      "source": [
        "! ls \"/gdrive/My Drive/DataSource_Full/data_speech_commands_v0.02/\"\n",
        "#! ls \"/gdrive/My Drive/Data_BigData/data_speech_commands_v0.02/\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_background_noise_  follow   marvin\tsheila\t\t  up\n",
            "backward\t    forward  nine\tsix\t\t  validation_list.txt\n",
            "bed\t\t    four     no\t\tstop\t\t  visual\n",
            "bird\t\t    go\t     off\ttest.csv\t  wow\n",
            "cat\t\t    happy    on\t\ttesting_list.txt  yes\n",
            "dog\t\t    house    one\tthree\t\t  zero\n",
            "down\t\t    learn    README.md\ttrain.csv\n",
            "eight\t\t    left     right\ttree\n",
            "five\t\t    LICENSE  seven\ttwo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6V8Ql0IApWf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a7f3ecd-812f-46f9-b686-886d9335a701"
      },
      "source": [
        "% cd DeepSpeech"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DeepSpeech\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEwk_6GVA6EZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cf64344c-632f-475e-cc1d-233f826620b7"
      },
      "source": [
        "! pip3 install  -r requirements_eval_tflite.txt\n",
        "! pip3 install  -r requirements_tests.txt\n",
        "! pip3 install  -r requirements_transcribe.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting absl-py==0.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n",
            "\r\u001b[K     |███▏                            | 10kB 19.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 20kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 30kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 40kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 61kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 81kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 92kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 102kB 5.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 5.4MB/s \n",
            "\u001b[?25hCollecting attrdict==2.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/97/28fe7e68bc7adfce67d4339756e85e9fcf3c6fd7f0c0781695352b70472c/attrdict-2.0.1-py2.py3-none-any.whl\n",
            "Collecting deepspeech\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/56/278c20c8fd211612d1979ecdb87693e6d3241eeb796f9400476c9252ba65/deepspeech-0.9.1-cp36-cp36m-manylinux1_x86_64.whl (9.2MB)\n",
            "\u001b[K     |████████████████████████████████| 9.2MB 5.9MB/s \n",
            "\u001b[?25hCollecting numpy==1.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/74/54c5f9bb9bd4dae27a61ec1b39076a39d359b3fb7ba15da79ef23858a9d8/numpy-1.16.0-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 217kB/s \n",
            "\u001b[?25hCollecting progressbar2==3.47.0\n",
            "  Downloading https://files.pythonhosted.org/packages/16/68/adc395e0a3c86571081c8a2e2daaa5b58270f6854276a089a0e9b5fa2c33/progressbar2-3.47.0-py2.py3-none-any.whl\n",
            "Collecting python-utils==2.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/a0/19119d8b7c05be49baf6c593f11c432d571b70d805f2fe94c0585e55e4c8/python_utils-2.3.0-py2.py3-none-any.whl\n",
            "Collecting six==1.13.0\n",
            "  Downloading https://files.pythonhosted.org/packages/65/26/32b8464df2a97e6dd1b656ed26b2c194606c16fe163c695a992b36c11cdf/six-1.13.0-py2.py3-none-any.whl\n",
            "Collecting pandas==0.25.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 68.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3->-r requirements_eval_tflite.txt (line 8)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3->-r requirements_eval_tflite.txt (line 8)) (2.8.1)\n",
            "Building wheels for collected packages: absl-py\n",
            "  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for absl-py: filename=absl_py-0.9.0-cp36-none-any.whl size=121933 sha256=ce1c264ec006d1a1bd228a3daaa7e85fbad63e248b3b3236137120bcfa993612\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/28/49/fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d\n",
            "Successfully built absl-py\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.16.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: nbclient 0.5.1 has requirement jupyter-client>=6.1.5, but you'll have jupyter-client 5.3.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: six, absl-py, attrdict, numpy, deepspeech, python-utils, progressbar2, pandas\n",
            "  Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Found existing installation: absl-py 0.10.0\n",
            "    Uninstalling absl-py-0.10.0:\n",
            "      Successfully uninstalled absl-py-0.10.0\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "  Found existing installation: python-utils 2.4.0\n",
            "    Uninstalling python-utils-2.4.0:\n",
            "      Successfully uninstalled python-utils-2.4.0\n",
            "  Found existing installation: progressbar2 3.38.0\n",
            "    Uninstalling progressbar2-3.38.0:\n",
            "      Successfully uninstalled progressbar2-3.38.0\n",
            "  Found existing installation: pandas 1.1.4\n",
            "    Uninstalling pandas-1.1.4:\n",
            "      Successfully uninstalled pandas-1.1.4\n",
            "Successfully installed absl-py-0.9.0 attrdict-2.0.1 deepspeech-0.9.1 numpy-1.16.0 pandas-0.25.3 progressbar2-3.47.0 python-utils-2.3.0 six-1.13.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas",
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from -r requirements_tests.txt (line 1)) (0.9.0)\n",
            "Collecting argparse\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
            "Collecting semver\n",
            "  Downloading https://files.pythonhosted.org/packages/0b/70/b84f9944a03964a88031ef6ac219b6c91e8ba2f373362329d8770ef36f02/semver-2.13.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py->-r requirements_tests.txt (line 1)) (1.13.0)\n",
            "Installing collected packages: argparse, semver\n",
            "Successfully installed argparse-1.4.0 semver-2.13.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting webrtcvad\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/34/e2de2d97f3288512b9ea56f92e7452f8207eb5a0096500badf9dfd48f5e6/webrtcvad-2.0.10.tar.gz (66kB)\n",
            "\r\u001b[K     |█████                           | 10kB 24.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 20kB 10.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 30kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 40kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: webrtcvad\n",
            "  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp36-cp36m-linux_x86_64.whl size=71331 sha256=385cbc5596bb2e06a38ddf1aa83e73b4aa5b41be2b972a9573289d2b862ec45c\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/2a/18/bd1aec41cac7c3051fe95d92a6ed446122ea31dc713c432fa1\n",
            "Successfully built webrtcvad\n",
            "Installing collected packages: webrtcvad\n",
            "Successfully installed webrtcvad-2.0.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3fPYRRD0x3Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22562c52-1d2e-49d9-9bdf-5afa40fe432b"
      },
      "source": [
        "!pip3 install --upgrade -e ."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/DeepSpeech\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.0a10) (1.16.0)\n",
            "Requirement already satisfied, skipping upgrade: progressbar2 in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.0a10) (3.47.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.0a10) (1.13.0)\n",
            "Collecting pyxdg\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/13/de39ddf4f9f9cea0c7684cd54a50d79c97ea99c9f6aed798fd13d0bd4609/pyxdg-0.27-py2.py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: attrdict in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.0a10) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.0a10) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: semver in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.0a10) (2.13.0)\n",
            "Collecting opuslib==2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/1d/7f/6dd65372355c8fd27cff78deb4fa0f2a6948f72a851035fb64aba6041b9f/opuslib-2.0.0.tar.gz\n",
            "Collecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/10/06b58f4120f26b603d905a594650440ea1fd74476b8b360dbf01e111469b/optuna-2.3.0.tar.gz (258kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 7.5MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sox\n",
            "  Downloading https://files.pythonhosted.org/packages/3f/67/1810e9a69956eb236967b7174c11fd8d8c2cdab051509286f72e6c7e147e/sox-1.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: bs4 in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.0a10) (0.0.1)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.0a10) (0.25.3)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.0a10) (2.23.0)\n",
            "Collecting numba==0.47.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/7d/f2b5ea8d5952115351e303d1aadbdd1c5b08f479d76456d43a5d7a3a8c88/numba-0.47.0-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 32.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: llvmlite==0.31.0 in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.0a10) (0.31.0)\n",
            "Requirement already satisfied, skipping upgrade: librosa in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.0a10) (0.6.3)\n",
            "Collecting soundfile\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Collecting ds_ctcdecoder==0.9.0-alpha.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/82/41fc294f5ca1998d7c6cfaf2841e17a6c8fb8c553a219905f5f7c770b7f1/ds_ctcdecoder-0.9.0a10-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 63.6MB/s \n",
            "\u001b[?25hCollecting tensorflow==1.15.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/64/7a19837dd54d3f53b1ce5ae346ab401dde9678e8f233220317000bfdb3e2/tensorflow-1.15.4-cp36-cp36m-manylinux2010_x86_64.whl (110.5MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5MB 22kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2->deepspeech-training==0.9.0a10) (2.3.0)\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/c8/c16d30bbed11a1722060014c246d124582d1f781b26f5859d8dacc3e08e1/colorlog-4.6.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: scipy!=1.4.0 in /usr/local/lib/python3.6/dist-packages (from optuna->deepspeech-training==0.9.0a10) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from optuna->deepspeech-training==0.9.0a10) (0.17.0)\n",
            "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.6/dist-packages (from optuna->deepspeech-training==0.9.0a10) (20.4)\n",
            "Collecting cmaes>=0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/3c/06c76ec8b54b9b1fad7f35e903fd25010fe3e0d41bd94cea5e6f12e0d651/cmaes-0.7.0-py3-none-any.whl\n",
            "Collecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/aa/c261dfd7f4ba6ce4701846a2689a46e2a172e012171de4378fc2926e3bf0/alembic-1.4.3-py2.py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 60.2MB/s \n",
            "\u001b[?25hCollecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/61/5b64d73b01c1218f55c894b5ec0fb89b32c6960b7f7b3ad9f5ac0c373b9d/cliff-3.5.0-py3-none-any.whl (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna->deepspeech-training==0.9.0a10) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna->deepspeech-training==0.9.0a10) (1.3.20)\n",
            "Requirement already satisfied, skipping upgrade: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4->deepspeech-training==0.9.0a10) (4.6.3)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->deepspeech-training==0.9.0a10) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->deepspeech-training==0.9.0a10) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->deepspeech-training==0.9.0a10) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->deepspeech-training==0.9.0a10) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->deepspeech-training==0.9.0a10) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->deepspeech-training==0.9.0a10) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from numba==0.47.0->deepspeech-training==0.9.0a10) (50.3.2)\n",
            "Requirement already satisfied, skipping upgrade: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->deepspeech-training==0.9.0a10) (2.1.9)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->deepspeech-training==0.9.0a10) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa->deepspeech-training==0.9.0a10) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa->deepspeech-training==0.9.0a10) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile->deepspeech-training==0.9.0a10) (1.14.3)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.0a10) (0.2.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 64.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.0a10) (1.33.2)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 63.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.0a10) (0.8.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.0a10) (0.35.1)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.0a10) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.0a10) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.0a10) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.0a10) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.0a10) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=20.0->optuna->deepspeech-training==0.9.0a10) (2.4.7)\n",
            "Collecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.1MB/s \n",
            "\u001b[?25hCollecting cmd2!=0.8.3,>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/54/af6e2703f064485d717cb311d3f9440cd302a823ba6d80a020b59eae166d/cmd2-1.4.0-py3-none-any.whl (133kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 67.4MB/s \n",
            "\u001b[?25hCollecting PrettyTable<0.8,>=0.7.2\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/30/4b0746848746ed5941f052479e7c23d2b56d174b82f4fd34a25e389831f5/prettytable-0.7.2.tar.bz2\n",
            "Collecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/a1/004f04ba411a8002b02aadb089fd6868116c12ddc9f6d576175e89d07587/stevedore-3.2.2-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna->deepspeech-training==0.9.0a10) (3.13)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/48/69046506f6ac61c1eaa9a0d42d22d54673b69e176d30ca98e3f61513e980/pbr-5.5.1-py2.py3-none-any.whl (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 55.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile->deepspeech-training==0.9.0a10) (2.20)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->deepspeech-training==0.9.0a10) (3.3.3)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->deepspeech-training==0.9.0a10) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.4->deepspeech-training==0.9.0a10) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna->deepspeech-training==0.9.0a10) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=1.6.0; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna->deepspeech-training==0.9.0a10) (2.0.0)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/4c/0b1d507ad7e8bc31d690d04b4f475e74c2002d060f7994ce8c09612df707/pyperclip-1.8.1.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna->deepspeech-training==0.9.0a10) (0.2.5)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna->deepspeech-training==0.9.0a10) (20.2.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=1.6.0; python_version < \"3.8\"->cmd2!=0.8.3,>=0.8.0->cliff->optuna->deepspeech-training==0.9.0a10) (3.4.0)\n",
            "Building wheels for collected packages: optuna\n",
            "  Building wheel for optuna (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optuna: filename=optuna-2.3.0-cp36-none-any.whl size=359761 sha256=603a937ac82609e5c849384837611993ade75f463bef717b9acdfae5e1ee56c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/91/19/64b0ec6b964f89c0695a9dc6db6f851d0b54c5381a5c9cadfb\n",
            "Successfully built optuna\n",
            "Building wheels for collected packages: opuslib, gast, PrettyTable, pyperclip\n",
            "  Building wheel for opuslib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for opuslib: filename=opuslib-2.0.0-cp36-none-any.whl size=11011 sha256=aa5df7c4dbb642b001b00a0b352d4f116c452bb277fb43c002cbf4212aa4f68d\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/6e/92/421e586c65ec15713ba6da6c22e4f09e84d37ee14df6272ee3\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=4547f9225e3b516262d36dc1809a0f114ae0e972fd1429e02156f9bb69223f67\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "  Building wheel for PrettyTable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PrettyTable: filename=prettytable-0.7.2-cp36-none-any.whl size=13700 sha256=466a3c07e90c1d82f90655ebab7555f0fed62a0ea74ee59c4ca8560546012d96\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/34/1c/3967380d9676d162cb59513bd9dc862d0584e045a162095606\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.1-cp36-none-any.whl size=11119 sha256=44e404711e62104d59b79b3ec1c61f7446b7e2c1438692a433bb7af34fdd5fc5\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/10/3a/c830e9bb3db2c93274ea1f213a41fabde0d8cf3794251fad0c\n",
            "Successfully built opuslib gast PrettyTable pyperclip\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement numba!=0.47,>=0.46, but you'll have numba 0.47.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.16.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pyxdg, opuslib, colorlog, cmaes, python-editor, Mako, alembic, colorama, pyperclip, cmd2, PrettyTable, pbr, stevedore, cliff, optuna, sox, numba, soundfile, ds-ctcdecoder, gast, tensorboard, tensorflow-estimator, keras-applications, tensorflow, deepspeech-training\n",
            "  Found existing installation: prettytable 1.0.1\n",
            "    Uninstalling prettytable-1.0.1:\n",
            "      Successfully uninstalled prettytable-1.0.1\n",
            "  Found existing installation: numba 0.48.0\n",
            "    Uninstalling numba-0.48.0:\n",
            "      Successfully uninstalled numba-0.48.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "  Running setup.py develop for deepspeech-training\n",
            "Successfully installed Mako-1.1.3 PrettyTable-0.7.2 alembic-1.4.3 cliff-3.5.0 cmaes-0.7.0 cmd2-1.4.0 colorama-0.4.4 colorlog-4.6.2 deepspeech-training ds-ctcdecoder-0.9.0a10 gast-0.2.2 keras-applications-1.0.8 numba-0.47.0 optuna-2.3.0 opuslib-2.0.0 pbr-5.5.1 pyperclip-1.8.1 python-editor-1.0.4 pyxdg-0.27 soundfile-0.10.3.post1 sox-1.4.1 stevedore-3.2.2 tensorboard-1.15.0 tensorflow-1.15.4 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmqoLlB2LWOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef956abf-adfc-43ca-b34a-41d3b8fb0012"
      },
      "source": [
        "! pip3 uninstall tensorflow\n",
        "! pip3 install 'tensorflow-gpu==1.15.2'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-1.15.4:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/freeze_graph\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow-1.15.4.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow_core/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-1.15.4\n",
            "Collecting tensorflow-gpu==1.15.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/ca/58e40e5077fa2a92004f398d705a288e958434f123938f4ce75ffe25b64b/tensorflow_gpu-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (411.0MB)\n",
            "\u001b[K     |████████████████████████████████| 411.0MB 35kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.15.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.16.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.35.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.13.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.33.2)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.8.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.15.2) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.3.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.2) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.4.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd-E9EqwDHlP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e24edd8-0e7d-4658-805b-ddec61d32f64"
      },
      "source": [
        "! pip3 install $(python3 util/taskcluster.py --decoder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: taskcluster.py [-h] [--target TARGET] [--arch ARCH]\n",
            "                      [--artifact ARTIFACT] [--source SOURCE]\n",
            "                      [--branch BRANCH]\n",
            "taskcluster.py: error: unrecognized arguments: --decoder\n",
            "\u001b[31mERROR: You must give at least one requirement to install (see \"pip help install\")\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN_Llp66EU-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30554070-809f-4bf6-cdf8-25e04e81d49d"
      },
      "source": [
        "!./DeepSpeech.py --train_files \"/gdrive/My Drive/DataSource_Full/data_speech_commands_v0.02/train.csv\" --test_files \"/gdrive/My Drive/DataSource_Full/data_speech_commands_v0.02/test.csv\" --export_dir \"/gdrive/My Drive/Data_op\" --checkpoint_dir \"/content/chkpoint\" -epochs 3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I1120 12:50:52.184184 139790494226304 utils.py:141] NumExpr defaulting to 4 threads.\n",
            "I Could not find best validating checkpoint.\n",
            "I Could not find most recent checkpoint.\n",
            "I Initializing all variables.\n",
            "I STARTING Optimization\n",
            "Epoch 0 |   Training | Elapsed Time: 0:54:40 | Steps: 4816 | Loss: 9.623873     Process ForkPoolWorker-3:\n",
            "Process ForkPoolWorker-2:\n",
            "Process ForkPoolWorker-4:\n",
            "Process ForkPoolWorker-1:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
            "    res = self._reader.recv_bytes()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
            "    buf = self._recv_bytes(maxlength)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
            "    buf = self._recv(4)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
            "    chunk = read(handle, remaining)\n",
            "KeyboardInterrupt\n",
            "I FINISHED optimization in 0:54:42.800897\n",
            "I Could not find best validating checkpoint.\n",
            "I Loading most recent checkpoint from /content/chkpoint/train-4416\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
            "I Loading variable from checkpoint: global_step\n",
            "I Loading variable from checkpoint: layer_1/bias\n",
            "I Loading variable from checkpoint: layer_1/weights\n",
            "I Loading variable from checkpoint: layer_2/bias\n",
            "I Loading variable from checkpoint: layer_2/weights\n",
            "I Loading variable from checkpoint: layer_3/bias\n",
            "I Loading variable from checkpoint: layer_3/weights\n",
            "I Loading variable from checkpoint: layer_5/bias\n",
            "I Loading variable from checkpoint: layer_5/weights\n",
            "I Loading variable from checkpoint: layer_6/bias\n",
            "I Loading variable from checkpoint: layer_6/weights\n",
            "Testing model on /gdrive/My Drive/DataSource_Full/data_speech_commands_v0.02/test.csv\n",
            "Test epoch | Steps: 4431 | Elapsed Time: 0:50:58                                Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
            "    target_list, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.\n",
            "  (0) Unknown: FileNotFoundError: [Errno 2] No such file or directory: '/gdrive/My Drive/DataSource_Full/data_speech_commands_v0.02/three/b5eb4f9b_nohash_0.wav'\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n",
            "    ret = func(*args)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 594, in generator_py_func\n",
            "    values = next(generator_state.get_iterator(iterator_id))\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/feeding.py\", line 114, in generate_values\n",
            "    for sample_index, sample in enumerate(samples):\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/augmentations.py\", line 221, in apply_sample_augmentations\n",
            "    yield from pool.imap(_augment_sample, timed_samples())\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/helpers.py\", line 102, in imap\n",
            "    for obj in self.pool.imap(fun, self._limit(it)):\n",
            "\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 735, in next\n",
            "    raise value\n",
            "\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 138, in _helper_reraises_exception\n",
            "    raise ex\n",
            "\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 290, in _guarded_task_generation\n",
            "    for i, x in enumerate(iterable):\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/helpers.py\", line 95, in _limit\n",
            "    for obj in it:\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/augmentations.py\", line 201, in timed_samples\n",
            "    for sample_index, sample in enumerate(samples):\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/sample_collections.py\", line 477, in __getitem__\n",
            "    return load_sample(sample_spec[0], label=sample_spec[2] if self.labeled else None)\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/sample_collections.py\", line 83, in load_sample\n",
            "    with open(filename, 'rb') as audio_file:\n",
            "\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/gdrive/My Drive/DataSource_Full/data_speech_commands_v0.02/three/b5eb4f9b_nohash_0.wav'\n",
            "\n",
            "\n",
            "\t [[{{node PyFunc}}]]\n",
            "\t [[IteratorGetNext]]\n",
            "  (1) Unknown: FileNotFoundError: [Errno 2] No such file or directory: '/gdrive/My Drive/DataSource_Full/data_speech_commands_v0.02/three/b5eb4f9b_nohash_0.wav'\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n",
            "    ret = func(*args)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 594, in generator_py_func\n",
            "    values = next(generator_state.get_iterator(iterator_id))\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/feeding.py\", line 114, in generate_values\n",
            "    for sample_index, sample in enumerate(samples):\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/augmentations.py\", line 221, in apply_sample_augmentations\n",
            "    yield from pool.imap(_augment_sample, timed_samples())\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/helpers.py\", line 102, in imap\n",
            "    for obj in self.pool.imap(fun, self._limit(it)):\n",
            "\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 735, in next\n",
            "    raise value\n",
            "\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 138, in _helper_reraises_exception\n",
            "    raise ex\n",
            "\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 290, in _guarded_task_generation\n",
            "    for i, x in enumerate(iterable):\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/helpers.py\", line 95, in _limit\n",
            "    for obj in it:\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/augmentations.py\", line 201, in timed_samples\n",
            "    for sample_index, sample in enumerate(samples):\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/sample_collections.py\", line 477, in __getitem__\n",
            "    return load_sample(sample_spec[0], label=sample_spec[2] if self.labeled else None)\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/sample_collections.py\", line 83, in load_sample\n",
            "    with open(filename, 'rb') as audio_file:\n",
            "\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/gdrive/My Drive/DataSource_Full/data_speech_commands_v0.02/three/b5eb4f9b_nohash_0.wav'\n",
            "\n",
            "\n",
            "\t [[{{node PyFunc}}]]\n",
            "\t [[IteratorGetNext]]\n",
            "\t [[layer_3/bias/read/_25]]\n",
            "0 successful operations.\n",
            "0 derived errors ignored.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"./DeepSpeech.py\", line 12, in <module>\n",
            "    ds_train.run_script()\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/train.py\", line 976, in run_script\n",
            "    absl.app.run(main)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/train.py\", line 952, in main\n",
            "    test()\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/train.py\", line 680, in test\n",
            "    samples = evaluate(FLAGS.test_files.split(','), create_model)\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/evaluate.py\", line 132, in evaluate\n",
            "    samples.extend(run_test(init_op, dataset=csv))\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/evaluate.py\", line 108, in run_test\n",
            "    session.run([batch_wav_filename, transposed, loss, batch_x_len, batch_y])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\n",
            "    raise type(e)(node_def, op, message)\n",
            "tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.\n",
            "  (0) Unknown: FileNotFoundError: [Errno 2] No such file or directory: '/gdrive/My Drive/DataSource_Full/data_speech_commands_v0.02/three/b5eb4f9b_nohash_0.wav'\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n",
            "    ret = func(*args)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 594, in generator_py_func\n",
            "    values = next(generator_state.get_iterator(iterator_id))\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/feeding.py\", line 114, in generate_values\n",
            "    for sample_index, sample in enumerate(samples):\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/augmentations.py\", line 221, in apply_sample_augmentations\n",
            "    yield from pool.imap(_augment_sample, timed_samples())\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/helpers.py\", line 102, in imap\n",
            "    for obj in self.pool.imap(fun, self._limit(it)):\n",
            "\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 735, in next\n",
            "    raise value\n",
            "\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 138, in _helper_reraises_exception\n",
            "    raise ex\n",
            "\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 290, in _guarded_task_generation\n",
            "    for i, x in enumerate(iterable):\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/helpers.py\", line 95, in _limit\n",
            "    for obj in it:\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/augmentations.py\", line 201, in timed_samples\n",
            "    for sample_index, sample in enumerate(samples):\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/sample_collections.py\", line 477, in __getitem__\n",
            "    return load_sample(sample_spec[0], label=sample_spec[2] if self.labeled else None)\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/sample_collections.py\", line 83, in load_sample\n",
            "    with open(filename, 'rb') as audio_file:\n",
            "\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/gdrive/My Drive/DataSource_Full/data_speech_commands_v0.02/three/b5eb4f9b_nohash_0.wav'\n",
            "\n",
            "\n",
            "\t [[{{node PyFunc}}]]\n",
            "\t [[IteratorGetNext]]\n",
            "  (1) Unknown: FileNotFoundError: [Errno 2] No such file or directory: '/gdrive/My Drive/DataSource_Full/data_speech_commands_v0.02/three/b5eb4f9b_nohash_0.wav'\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n",
            "    ret = func(*args)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 594, in generator_py_func\n",
            "    values = next(generator_state.get_iterator(iterator_id))\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/feeding.py\", line 114, in generate_values\n",
            "    for sample_index, sample in enumerate(samples):\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/augmentations.py\", line 221, in apply_sample_augmentations\n",
            "    yield from pool.imap(_augment_sample, timed_samples())\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/helpers.py\", line 102, in imap\n",
            "    for obj in self.pool.imap(fun, self._limit(it)):\n",
            "\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 735, in next\n",
            "    raise value\n",
            "\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 138, in _helper_reraises_exception\n",
            "    raise ex\n",
            "\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 290, in _guarded_task_generation\n",
            "    for i, x in enumerate(iterable):\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/helpers.py\", line 95, in _limit\n",
            "    for obj in it:\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/augmentations.py\", line 201, in timed_samples\n",
            "    for sample_index, sample in enumerate(samples):\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/sample_collections.py\", line 477, in __getitem__\n",
            "    return load_sample(sample_spec[0], label=sample_spec[2] if self.labeled else None)\n",
            "\n",
            "  File \"/content/DeepSpeech/training/deepspeech_training/util/sample_collections.py\", line 83, in load_sample\n",
            "    with open(filename, 'rb') as audio_file:\n",
            "\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/gdrive/My Drive/DataSource_Full/data_speech_commands_v0.02/three/b5eb4f9b_nohash_0.wav'\n",
            "\n",
            "\n",
            "\t [[{{node PyFunc}}]]\n",
            "\t [[IteratorGetNext]]\n",
            "\t [[layer_3/bias/read/_25]]\n",
            "0 successful operations.\n",
            "0 derived errors ignored.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIBsZABswQUq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d142b3f9-0993-480b-b0c7-c2c57a377de1"
      },
      "source": [
        "! ls /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chkpoint  DeepSpeech  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}